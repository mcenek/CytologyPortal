#include "ClumpSegmentation.h"
#include "opencv2/opencv.hpp"
#include "../VLFeatWrapper.cpp"
#include "LSM.h"
#include "SegmenterTools.h"

using namespace std;

namespace segment {
    cv::Mat drlse_denoise(cv::Mat phi, cv::Mat g, float lambda, float mu, float alpha, float epsilon,
                          float timestep) {
        int iter_in = 2;
        vector <cv::Mat> gGradient = calcGradient(g);
        cv::Mat vx = getGradientX(gGradient);
        cv::Mat vy = getGradientY(gGradient);
        for (int i = 0; i < iter_in; i++) {
            phi = neumannBoundCond(phi);
            vector <cv::Mat> gradient = calcGradient(phi);
            vector <cv::Mat> curvatureXY = calcCurvatureXY(gradient);
            cv::Mat Nx = curvatureXY[0];
            cv::Mat Ny = curvatureXY[1];
            cv::Mat curvature = calcDivergence(Nx, Ny);
            cv::Mat regularizer = calcSignedDistanceReg(phi);
            cv::Mat dirac = calcDiracDelta(phi, epsilon);
            cv::Mat areaTerm = dirac.mul(g);
            cv::Mat edgeTerm = dirac.mul(vx.mul(Nx) + vy.mul(Ny)) +
                               dirac.mul(g).mul(curvature);
            phi += timestep * (mu * regularizer +
                               lambda * edgeTerm +
                               alpha * areaTerm);
        }
        return phi;
    }

    /*
         runQuickshift takes an image and params and runs Quickshift on it, using the VL_Feat implementation
         Returns:
         cv::Mat = image after quickshift is applied
         Params:
         cv::Mat img = the image
         int kernelsize = the kernel or window size of the quickshift applied
         int maxdist = the largest distance a pixel can be from it's root
       */
    cv::Mat runQuickshift(cv::Mat img, int kernelsize, int maxdist, bool debug) {
        int channels = img.channels();
        int width = img.cols;
        int height = img.rows;

        cv::Mat tempMat;
        img.copyTo(tempMat);
        tempMat.convertTo(tempMat, CV_64FC3, 1 / 255.0);
        double *cvimg = (double *) tempMat.data;
        double *vlimg = (double *) calloc(channels * width * height, sizeof(double));

        // create VLFeatWrapper object
        VLFeatWrapper vlf_wrapper = VLFeatWrapper(width, height, channels);
        vlf_wrapper.debug = debug;
        vlf_wrapper.verifyVLFeat();

        // apply quickshift from VLFeat
        vlf_wrapper.convertOPENCV_VLFEAT(cvimg, vlimg);
        int superpixelcount = vlf_wrapper.quickshift(vlimg, kernelsize, maxdist);
        vlf_wrapper.convertVLFEAT_OPENCV(vlimg, cvimg);

        cv::Mat postQuickShift = cv::Mat(height, width, CV_64FC3, cvimg);
        cv::Mat outimg;
        postQuickShift.copyTo(outimg);
        outimg.convertTo(outimg, CV_8UC3, 255);
        free(vlimg);

        if (debug) printf("Super pixels found via quickshift: %i\n", superpixelcount);
        return outimg;
    }

    /*
      runCanny runs canny edge detection on an image, and dilates and erodes it to close holes
      Returns:
      cv::Mat = edges found post dilate/erode
      Params:
      cv::Mat img = image to find edged in
      int threshold1 = first threshold for the hysteresis procedure.
      int threshold2 = second threshold for the hysteresis procedure.
    */
    cv::Mat runCanny(cv::Mat img, int threshold1, int threshold2, bool erodeFlag) {
        cv::Mat postEdgeDetection;
        img.copyTo(postEdgeDetection);
        cv::Mat blurred;
        cv::blur(img, blurred, cv::Size(2, 2)); //TODO: Shouldn't this be a cv::GaussianBlur..?
        cv::Canny(blurred, postEdgeDetection, threshold1, threshold2);

        if (erodeFlag) {
            // TODO these values for dilate and erode possibly should be configurable
            cv::Mat kernel = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(2, 2));
            kernel = cv::Mat();
            cv::dilate(postEdgeDetection, postEdgeDetection, kernel, cv::Point(-1, -1), 1);
            cv::erode(postEdgeDetection, postEdgeDetection, kernel, cv::Point(-1, -1), 1);
        }

        return postEdgeDetection;
    }

    vector<vector<cv::Point>> runFindConvexHulls(vector<vector<cv::Point>> contours) {
        vector<vector<cv::Point>> hulls(contours.size());
        for (unsigned int i = 0; i < contours.size(); i++)
            cv::convexHull(cv::Mat(contours[i]), hulls[i], false);
        return hulls;
    }

    /*
      runGmm creates 2 Gaussian Mixture Models, one for cell pixels and one for background pixels,
      then returns the result of the labels generated by these models
      Returns:
      cv::Mat = labels found per pixel
      Params:
      cv::Mat img = image to process
      vector<vector<cv::Point>> hulls = convex hulls to provide initial labeling
      int maxGmmIterations = maximum number of iterations to allow the gmm to train
    */
    cv::Mat runGmm(cv::Mat img, vector<vector<cv::Point>> hulls, int maxGmmIterations) {
        cv::Mat grayscaleImg;
        img.convertTo(grayscaleImg, CV_8UC3);
        cv::cvtColor(grayscaleImg, grayscaleImg, CV_BGR2GRAY);

        cv::Ptr<cv::CLAHE> clahe = cv::createCLAHE(2);
        clahe->apply(grayscaleImg, grayscaleImg);


        grayscaleImg.convertTo(grayscaleImg, CV_64FC1);
        grayscaleImg = grayscaleImg.reshape(0, grayscaleImg.rows * grayscaleImg.cols);

        //Foreground black, background white
        cv::Mat probCluster1 = cv::Mat::ones(img.rows, img.cols, CV_32F);
        cv::drawContours(probCluster1, hulls, -1, (0), -1);
        probCluster1 = probCluster1.reshape(0, img.rows * img.cols);

        //Foreground white, background black
        cv::Mat probCluster2;
        cv::bitwise_not(probCluster1, probCluster2);

        cv::Mat initialProbMat;
        cv::hconcat(probCluster1, probCluster2, initialProbMat);

        cv::Mat labels;
        cv::Ptr<cv::ml::EM> cell_gmm;
        cv::TermCriteria termCrit = cv::TermCriteria();
        termCrit.type = cv::TermCriteria::COUNT;
        termCrit.maxCount = maxGmmIterations;
        cell_gmm = cv::ml::EM::create();
        cell_gmm->setTermCriteria(termCrit);
        cell_gmm->setClustersNumber(2);
        cell_gmm->trainM(grayscaleImg, initialProbMat, cv::noArray(), labels, cv::noArray());

        labels = labels.reshape(0, img.rows);

        cv::Mat outimg;
        labels.copyTo(outimg);
        outimg.convertTo(outimg, CV_8U, 255);

        outimg = runGmmCleanup(img, outimg);
        return outimg;
    }

    cv::Mat runGmmCleanup(cv::Mat im, cv::Mat gmmPredictions) {
        float timestep = 5;
        float mu = 0.04;
        float epsilon = 1.5;

        cv::Mat edgeEnforcer = calcEdgeEnforcer(im);
        cv::Mat initialPhi;

        gmmPredictions.convertTo(initialPhi, CV_32FC1);
        for (int i = 0; i < initialPhi.rows; i++) {
            float *row = initialPhi.ptr<float>(i);
            for (int j = 0; j < initialPhi.cols; j++) {
                float value = row[j];
                if (value != 0) row[j] = -2;
                else row[j] = 2;
            }
        }
        cv::Mat phi = initialPhi;
        int iter_out = 3;
        float alpha = -2.5;
        float lambda = 5;

        for (int i = 0; i < iter_out; i++) {
            phi = drlse_denoise(phi, edgeEnforcer, lambda, mu, alpha, epsilon, timestep);
        }
        alpha = 0;
        phi = drlse_denoise(phi, edgeEnforcer, lambda, mu, alpha, epsilon, timestep);
        cv::bitwise_not(phi, phi);
        return phi;
    }

    /*
    findFinalClumpBoundaries takes an image and a threshold and returns all the contours whose
    size is greater than the threshold
    Returns:
    vector<vector<cv::Point> > = the contours found
    Params:
    cv::Mat img = the input image
    int minAreaThreshold = the minimum area, all contours smaller than this are discarded
    */
    vector<vector<cv::Point>> findFinalClumpBoundaries(cv::Mat img, double minAreaThreshold) {
        //cv::threshold(img, img, 1.9, 1, CV_THRESH_BINARY);
        img.convertTo(img, CV_8UC1);
        vector<vector<cv::Point>> contours;
        cv::findContours(img, contours, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_NONE);
        vector<vector<cv::Point> > clumpBoundaries = vector<vector<cv::Point> >();
        for (unsigned int i = 0; i < contours.size(); i++) {
            vector<cv::Point> contour = contours[i];
            double area = cv::contourArea(contour);
            if (area > minAreaThreshold) {
                // TODO add debug check or rm
                if (false) printf("Adding new clump, size:%f threshold:%f\n", area, minAreaThreshold);
                clumpBoundaries.push_back(contour);
            }
        }
        return clumpBoundaries;
    }
}